{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import model_file\n",
    "import module_split as module\n",
    "\n",
    "import RF_module as RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/lynnle/MonkeyProject/git/models/RFmasked/SyntheticTraining/module_split.py:39: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  param = Variable(param, volatile=True)\n"
     ]
    }
   ],
   "source": [
    "dot_numbers_test = np.load(f'testing/testing_synth191final.npy')\n",
    "dot_numbers_train = np.load(f'training/training_synth191final.npy')\n",
    "\n",
    "runname = 'synthetic_loaddot'\n",
    "device = 1\n",
    "cuda0 = torch.device(f'cuda:{device}')\n",
    "batch_size = 4\n",
    "epochs = 1\n",
    "in_channels=2\n",
    "\n",
    "if in_channels == 2:\n",
    "    inputtype = 'V1_V4'\n",
    "if in_channels == 191:\n",
    "    inputtype = 'all_channels'\n",
    "\n",
    "# -----\n",
    "# Model, loss, & optimizer\n",
    "# -----\n",
    "model = model_file.ResblocksDeconv(in_channels, (240,240))\n",
    "\n",
    "if device >= 0:\n",
    "    model.cuda(device)\n",
    "# lossFunction = module.LossFunction(device)\n",
    "lossFunction = module.VGGLoss(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "hori_means, verti_means, std_avg = RF.extract_means_std()\n",
    "\n",
    "# -----\n",
    "# Inputs:\n",
    "# Will be dot number times the gaus\n",
    "# ------\n",
    "gaus = module.load_gausdata()\n",
    "\n",
    "# ------\n",
    "# Targets:\n",
    "# are the masked nn_seen_torch, correspponding to the dot_number.\n",
    "# ------\n",
    "nn_seen_torch = torch.from_numpy(module.load_ydata())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------\n",
    "# Training\n",
    "# ------\n",
    "training_iterator = module.make_iterator_unique(dot_numbers_train, 'training', batch_size, shuffle = True)\n",
    "# ------\n",
    "# Testing\n",
    "# ------\n",
    "testing_iterator = module.make_iterator_unique(dot_numbers_test, 'testing', batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this training loop, in order to make the correct input data, we need to multiply dot numbers with the gaussian blurs. No need for calculating dot numbers with the nn_seen anymore. \n",
    "\n",
    "Iterator needs to output dot numbers, which will be multiplied with gaus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1317/2000 [04:35<02:19,  4.88it/s]"
     ]
    }
   ],
   "source": [
    "# EPOCHS\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "confidence_mask = RF.make_confidence_mask(hori_means, verti_means, std_avg)\n",
    "confidence_mask = torch.from_numpy(confidence_mask.astype('float32')).to(cuda0)\n",
    "for e in range(epochs):  # loop over the dataset multiple times\n",
    "    loss_train = 0\n",
    "    model.train()\n",
    "\n",
    "    for dot_number, img_indices  in tqdm(training_iterator, total=len(training_iterator)):\n",
    "        # -----\n",
    "        # Inputs\n",
    "        # -----\n",
    "        \n",
    "        gaus_expand_to_batch = gaus.expand([len(img_indices), 191, 240, 240])\n",
    "        weight_images = dot_number[:,:,np.newaxis, np.newaxis].expand([len(img_indices), 191, 240, 240])     \n",
    "        \n",
    "        # We want to use the dot number and repeat it (expand to gaus) such that it will have the same shape. \n",
    "        #Then you multiply with the gaus_exapnd_go_batch!\n",
    "        inputs = module.select_type_inputs(inputtype, gaus_expand_to_batch, weight_images)\n",
    "        inputs = inputs.to(cuda0)\n",
    "\n",
    "        # -----\n",
    "        # Targets\n",
    "        # -----\n",
    "        target_batch = nn_seen_torch[img_indices]\n",
    "        target_batch = target_batch.transpose(3,1).transpose(2,3)\n",
    "        target_batch = target_batch.to(cuda0)\n",
    "\n",
    "        # -----\n",
    "        # Outputs\n",
    "        # -----\n",
    "        optimizer.zero_grad()\n",
    "        y = model(inputs) \n",
    "\n",
    "        # -----\n",
    "        # Before calculating loss, make a mask\n",
    "        # -----\n",
    "        y *= confidence_mask.expand_as(y)\n",
    "        target_batch *= confidence_mask.expand_as(target_batch)\n",
    "\n",
    "        # ------\n",
    "        # Loss \n",
    "        # ------\n",
    "        train_loss = lossFunction(y, target_batch)\n",
    "\n",
    "        # ------\n",
    "        # Backward & update\n",
    "        # ------\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ------\n",
    "        # Loss \n",
    "        # ------\n",
    "        loss_train += train_loss.sum().item()\n",
    "    losses_train.append(loss_train/len(training_iterator.sampler))\n",
    "    \n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_test = 0\n",
    "        model.eval()\n",
    "        for dot_number, img_indices in tqdm(testing_iterator, total=len(testing_iterator)):\n",
    "            # -----\n",
    "            # Inputs\n",
    "            # -----\n",
    "            gaus_expand_to_batch = gaus.expand([len(img_indices), 191, 240, 240])\n",
    "            weight_images = dot_number[:,:,np.newaxis, np.newaxis].expand([len(img_indices), 191, 240, 240])     \n",
    "\n",
    "            # We want to use the dot number and repeat it (expand to gaus) such that it will have the same shape. \n",
    "            #Then you multiply with the gaus_exapnd_go_batch!\n",
    "            inputs = module.select_type_inputs(inputtype, gaus_expand_to_batch, weight_images)\n",
    "            inputs = inputs.to(cuda0)\n",
    "\n",
    "            # -----\n",
    "            # Targets\n",
    "            # -----\n",
    "            target_batch = nn_seen_torch[img_indices]\n",
    "            target_batch = target_batch.transpose(3,1).transpose(2,3)\n",
    "            target_batch = target_batch.to(cuda0)\n",
    "            # -----\n",
    "            # Outputs\n",
    "            # -----\n",
    "            y = model(inputs)\n",
    "            y *= confidence_mask.expand_as(y)\n",
    "            target_batch *= confidence_mask.expand_as(target_batch)\n",
    "            # ------\n",
    "            # Loss \n",
    "            # ------\n",
    "            test_loss = lossFunction(y, target_batch)\n",
    "            loss_test += test_loss.sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
